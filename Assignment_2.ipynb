{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN/I4eU4vciXbz4uuUJBA6O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngzhankang/Deep-Learning_ca2/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BYpyxj0Fk5Y"
      },
      "source": [
        "# Assignment 2\r\n",
        "Done by : \r\n",
        "- P1935727 Ng Zhan Kang\r\n",
        "- P1935232 Triston Loh\r\n",
        "\r\n",
        "Class of DIT/FT/2B/11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw-5Jb2IFo8z"
      },
      "source": [
        "---\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfuLF6F5Fqfy"
      },
      "source": [
        "### 1.1 Ensuring 0% Util\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Ensure that our slot give by Google is not utilized yet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BGRQF99FXN0"
      },
      "source": [
        "# to ensure that the current gpu utilization is 0\r\n",
        "# memory footprint support libraries/code\r\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\r\n",
        "!pip install gputil\r\n",
        "!pip install psutil\r\n",
        "!pip install humanize\r\n",
        "import psutil\r\n",
        "import humanize\r\n",
        "\r\n",
        "import os\r\n",
        "import GPUtil as GPU\r\n",
        "GPUs = GPU.getGPUs()\r\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\r\n",
        "gpu = GPUs[0]\r\n",
        "def printm():\r\n",
        " process = psutil.Process(os.getpid())\r\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\r\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\r\n",
        "printm() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqrHcr-0FsgA"
      },
      "source": [
        "### 1.2. Forcing Utils To 0% To Get A Clean Cluster\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Please do not use this step unless the cluster you are allocated to is quite full."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTOEqthPFtzb"
      },
      "source": [
        "## if utilization is > 0, run this code(keep running this cell and the above cell till the util number is 0%):\r\n",
        "## NOTE THAT RUNNING THIS MIGHT KILL GPU SESSION AND RESULT IN DATA LOSS(NOT ADVICABLE TO KEEP ON REUSING)\r\n",
        "# !kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzwbFfRDFvLA"
      },
      "source": [
        "---\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5Xuk11lFxdF"
      },
      "source": [
        "# 2.Ensuring GPU Is Utilized In Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUlSke_yFy_u"
      },
      "source": [
        "### 2.1. See the list of available devices\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "This entire section can be omitted if users are not utilizing GPU at all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ayxTCVYFvrc"
      },
      "source": [
        "from tensorflow.python.client import device_lib\r\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HMHDnUiF046"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyQoebJvF2QE"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSKJeK-TF0ju"
      },
      "source": [
        "---\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0S6R2BRF8CT"
      },
      "source": [
        "# 3.Background Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10sJ5h7qF5Zx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}