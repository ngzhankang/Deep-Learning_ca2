{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM2KDHoQL4Nyqv/sahhGAXH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngzhankang/Deep-Learning_ca2/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK3pMITo86WX"
      },
      "source": [
        "# Assignment 2\r\n",
        "Done by : \r\n",
        "- P1935727 Ng Zhan Kang\r\n",
        "- P1935232 Triston Loh\r\n",
        "\r\n",
        "Class of DIT/FT/2B/11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGmCBIj1_TW6"
      },
      "source": [
        "---\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIlpF8qq_V7V"
      },
      "source": [
        "# 1.Setting Up Working Environment In Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glob1Jhc_X1v"
      },
      "source": [
        "### 1.1 Ensuring 0% Util\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Ensure that our slot give by Google is not utilized yet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwGnVjjQ_SsP"
      },
      "source": [
        "# to ensure that the current gpu utilization is 0\r\n",
        "# memory footprint support libraries/code\r\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\r\n",
        "!pip install gputil\r\n",
        "!pip install psutil\r\n",
        "!pip install humanize\r\n",
        "import psutil\r\n",
        "import humanize\r\n",
        "\r\n",
        "import os\r\n",
        "import GPUtil as GPU\r\n",
        "GPUs = GPU.getGPUs()\r\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\r\n",
        "gpu = GPUs[0]\r\n",
        "def printm():\r\n",
        " process = psutil.Process(os.getpid())\r\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\r\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\r\n",
        "printm() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY-a4arr_aA9"
      },
      "source": [
        "### 1.2. Forcing Utils To 0% To Get A Clean Cluster\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Please do not use this step unless the cluster you are allocated to is quite full."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzMqWIXH_bZm"
      },
      "source": [
        "## if utilization is > 0, run this code(keep running this cell and the above cell till the util number is 0%):\r\n",
        "## NOTE THAT RUNNING THIS MIGHT KILL GPU SESSION AND RESULT IN DATA LOSS(NOT ADVICABLE TO KEEP ON REUSING)\r\n",
        "# !kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Wy7u0Sh_cz4"
      },
      "source": [
        "---\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqfZCPrF_fLu"
      },
      "source": [
        "# 2.Ensuring GPU Is Utilized In Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Hb4KZ_d_gyS"
      },
      "source": [
        "### 2.1. See the list of available devices\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "This entire section can be omitted if users are not utilizing GPU at all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8vv2q6W_dQk"
      },
      "source": [
        "from tensorflow.python.client import device_lib\r\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb6ywvvm_i-N"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrpWV4r6_j3j"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKCn0Nse_kz5"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cSqFEAP_luo"
      },
      "source": [
        "---\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irqZu3_qAGaj"
      },
      "source": [
        "# 3.Background Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T79rw9w_mLV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}